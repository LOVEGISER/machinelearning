
# 第9部分：聚类
聚类试图将数据集中的样本划分为若干个通常不相交的子集，成为一个“族”，每个族代表一些潜在的概念，这些概念对算法来说是未知的。
##聚类度量
聚类试图将数据集中的样本划分为若干个通常不相交的子集，那么什么样的聚类效果好么，直观来看我们希望同类样本之间彼此尽可能相似，不同类样本之间相似度尽可能大。即“族内相似度高”；“族见相似度低”。
聚类度量分为2类：
1：将聚类结果和某个参数模型进行比较，称为外部指标。
2：直接参考聚类结果而不需要利用任何参考模型，称为内部指标。
###外部指标
对数据集$D=\{x_1,x_2\cdots,x_m\}$,假定通过聚类给出(预测出)的族划分为$C=\{C_1,C_2\cdots,C_k\}$, 参考模型给出族$C^*=\{C_1^*,C_2^*\cdots,C_s^*\}$.相应的里$\lambda,\lambda^* $分别表示$C,C^*$对应的标记向量，则将样本两两配对如下：
$$
a=|SS|,SS=\{(x_i,x_j) | \lambda_i = \lambda_j, \lambda_i^* = \lambda_j^*,(i \leq j) \}
$$
$$
b=|SD|,SD=\{(x_i,x_j) | \lambda_i = \lambda_j, \lambda_i^* \neq \lambda_j^*,(i \leq j) \}
$$
$$
c=|DS|,DS=\{(x_i,x_j) | \lambda_i \neq \lambda_j, \lambda_i^* = \lambda_j^*,(i \leq j) \}
$$
$$
d=|DD|,DD=\{(x_i,x_j) | \lambda_i \neq \lambda_j, \lambda_i^* \neq\lambda_j^*,(i \leq j) \}
$$
其中SS包含了在$C$中属于同一个族在$C^*$中也属于相同族的样本对；集合SD包含了在$C$中属于同一个族在$C^*$中不属于相同族的样本对......
,由于每个样本对$(x_i,x_j)$仅能出现在一个集合中，因此：
$$
a+b+c+d={{m(m-1)} \over 2}
$$
基于上式可导出下面常用的度量距离的外部指标：
* Jaccard 系数（Jaccard Coefficient ,简称JC）
$$
JC ={ {a} \over {a+b+c}}
$$
* FM指数（Fowlkes and Mallows Index ，简称FMI）
$$
FMI = \sqrt{{a \over {a+b}}.{a \over {a+c}}}
$$
* Rand指数（Rand Index，简称RI）
$$
RI ={ {2(a+d)} \over {m(m-1)}}
$$
显然上述的结果在[0,1]之间，值越大越好。
###内部指标
$$
avg(C)={ 2 \over {|C|(|C|-1)}}\sum_{1\leq i\leq j\leq |C|}dist(x_i,x_j)
$$

$$
diam(C)=max_{1\leq i\leq j\leq |C|}dist(x_i,x_j)
$$
$$
d_{min}(C_i,C_j)=min_{x_i \in C_i ；x_j \in C_j}dist(x_i,x_j)
$$
$$
d_{cen}(C_i,C_j)=dist(\mu_i,\mu_j)
$$
其中dist(.,.)表示两个样本之间的距离,
$$\mu ={1 \over |c|}\sum_{a \leq j \leq |c|}  $$
1：显然$avg(C)$代表C类样本内部见平局距离；
2：$diam(C)$代表样本见最远距离
3：$d_{min}(C_i,C_j)$对应于族$(C_i,C_j)$最近样本间距离
4：$d_{cen}(C_i,C_j)$对应于族$(C_i,C_j)$中心点距离
则有以下指标：
* DB指数（Davies-Bouldin Index 简称DBI）
$$
DBI={1\over k} \sum_{i=1}^kmax_{j \neq j}{  {avg(C_i)+avg(C_j)} \over{d_{cen}(\mu_i,\mu_j)} }
$$
* Dunn指数（Dunn Index,简称DI）
$$
DI = min_{1 \leq i \leq j} \{ min_{j \neq i}  ( { d_{min}(C_i,C_j) \over {max_{a \leq l \leq k}diam(C_l)}} ) \}
$$
###距离指标
对距离度量需要满足以下基本性质：
1：非负性： $ dist(x_i,x_j) \geq 0$
2：对称性：$ dist(x_i,x_j) =dist(x_j,x_i)$
3：直递性： $ dist(x_i,x_j) \leq  dist(x_i,x_k) +  dist(x_k,x_j)$
给定样本$x_i$常用的**“闵可夫斯基距离”**
$$
dist_{mk}(x_i,x_j) = (\sum_{u=1}^n|x_{i\mu}-x_{j\mu}|^p)^{1 \over p}
$$
* 当p=2时，**“闵可夫斯基距离即欧式距离”**

$$
dist_{mk}(x_i,x_j) = ||x_i-x_j||_2 = \sqrt{\sum_{\mu=1}^n |x_{i\mu}-x_{j\mu}|^2}
$$
* 当p=2时，**“闵可夫斯基距离即曼哈顿距离”**

$$
dist_{mk}(x_i,x_j) = ||x_i-x_j||_1 = {\sum_{\mu=1}^n |x_{i\mu}-x_{j\mu}|}
$$
显然闵可夫斯基距离主要适用于有序性的数据。
* 对于无序性数据可采样DVM（value diiference metric）,用$m_{u,a}$表示在属性u上取值为a的样本数，$m_{u,a,i}$表示第i个样本族中在属性u上取值为a的样本树，k为样本族树，则属性u上两个了离散值a，b之间的DVM距离为：
$$
DVM_p(a,b)=\sum_{i=1}^k| { m_{u,a,i} \over m_{u,a} } - {m_{u,b,i} \over m_{u,b} } |^p
$$
于是将闵可夫斯基距离和DVM距离集合可处理混合属性。
* 假定有$n_c$个有序属性，$n-n_c$个无序属性，令有序属性排列在无序属性前，则：
$$
MinkovDM_p(x_i,x_j)=(  \sum_{u=1}^{n_c}|x_{i\mu}-x_{j\mu}|^p) +\sum_{u=n_c}^{n}DVM_p(x_iu-x_ju)   )^{1 \over p}
$$
当空间中不同属性重要性不同时加权重：
$$
dist_{mk}(x_i,x_j) = (w_1|x_{i1}-x_{j1}|^p+\cdots +w_n|x_{in}-x_{jn}|^p)^{1 \over p}
$$
其中权重$w_i \geq 0$，表示不同属性重要性，通常 $\sum_{i=1}^n =1$

















