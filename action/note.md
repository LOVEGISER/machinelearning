# 常用的机器学习算法
		
| 监督学习 | 非监督学习          |
| ----------| ---------|
| k邻近值算法      | k均值|
| 朴素贝叶斯算法      | DBSCAN|
| 支持向量机      | 最大期望算法|
| 决策树      | parzen窗设计|
| 线性回归      | |
| 局部加权线性回归      |  |
 | Ridge回归      |  |
 | Lasso回归      |  |
 # 如何选择机器学习算法
  1：如果想要预测目标变量的值， 则可以选择监督学习算法，否则可以选择无监督学习算法。  
 2：确定选择监督学习算法之后，需要进一步确定目标变量类型，如果目标变量是离散型，
 如是/否、1/2/3、― 冗或者红/黄/黑等，则可以选择`分类器算法`；如果目标变量是连续型的数值，
 如0.0~ 100.00、-999~999或者+00~-00等 ，则需要选择`回归算法`。  
 3：如果不想预测目标变量的值，则可以选择无监督学习算法。进一步分析是否需要将数据划分
为离散的组。如果这是唯一的需求，则使用`聚类算法`；如果还需要估计数据与每个分组的相似程
度 ，则需要使用`密度估计算法`。

##  k-近邻算法
简单地说，谷近邻算法采用测量不同特征值之间的距离方法进行分类。  
优 点 ：精度高、对异常值不敏感、无数据输入假定。  
缺点：计算复杂度高、空间复杂度高。    
适用数据范围：数值型和标称型。   
###工作原理是：
存在一个样本数据集合，也称作训练样本集，并且样本集中每个数据都存在标签，即我们知道样本集中每一数据
与所属分类的对应关系。输人没有标签的新数据后， 将新数据的每个特征与样本集中数据对应的
特征进行比较，然后算法提取样本集中特征最相似数据（最 近 邻 ）的分类标签。
